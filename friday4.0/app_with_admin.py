"""
AGRI-FRIDAY - USER APP (CLOUD-SAFE)
Reads configuration from admin panel
Run admin panel: streamlit run admin.py
Setup: pip install -r requirements.txt && echo "GROQ_API_KEY=your_key" > .env
Run user app: streamlit run app_with_admin.py
"""

import streamlit as st
import cv2
import os
import json
from groq import Groq
from langchain_groq import ChatGroq
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
import tempfile
import edge_tts
import asyncio
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import av

# Load configs from admin panel
def load_config(file, default):
    if os.path.exists(file):
        with open(file, 'r') as f:
            return json.load(f)
    return default

THEME_CONFIG = load_config("theme_config.json", {
    "primary_color": "#00ff88",
    "background_gradient_start": "#0f0c29",
    "background_gradient_mid": "#302b63",
    "background_gradient_end": "#24243e",
    "glass_opacity": "0.05",
    "glass_blur": "10px",
    "font_family": "Inter",
    "app_name": "AGRI-FRIDAY",
    "app_tagline": "AI Agriculture Assistant"
})

SETTINGS = load_config("settings_config.json", {
    "enable_camera": True,
    "enable_voice": True,
    "enable_rag": True,
    "groq_model": "llama-3.3-70b-versatile",
    "whisper_model": "whisper-large-v3-turbo",
    "max_tokens": 500,
    "temperature": 0.7,
    "chunk_size": 1000,
    "chunk_overlap": 200
})

GROQ_KEY = os.getenv("GROQ_API_KEY", "")
PDF_FOLDER = "knowledge_base"

def init_ai():
    if not GROQ_KEY: return None, None
    client = Groq(api_key=GROQ_KEY)
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    try:
        vectorstore = Chroma(persist_directory="./db", embedding_function=embeddings)
    except:
        vectorstore = None
    return client, vectorstore

def ask_ai(query, client, vectorstore):
    if not client: return "‚ö†Ô∏è Set GROQ_API_KEY in the environment."
    
    if SETTINGS['enable_rag'] and vectorstore:
        llm = ChatGroq(
            temperature=SETTINGS['temperature'], 
            model_name=SETTINGS['groq_model'], 
            groq_api_key=GROQ_KEY,
            max_tokens=SETTINGS['max_tokens']
        )
        qa = RetrievalQA.from_chain_type(
            llm=llm, 
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
        )
        return qa.invoke(query)["result"]
    else:
        resp = client.chat.completions.create(
            model=SETTINGS['groq_model'],
            messages=[{"role": "user", "content": query}],
            temperature=SETTINGS['temperature'],
            max_tokens=SETTINGS['max_tokens']
        )
        return resp.choices[0].message.content

def speech_to_text(audio_bytes):
    """Processes audio files generated by st.audio_input"""
    if not SETTINGS['enable_voice'] or not audio_bytes: return ""
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(audio_bytes.read())
        tmp_path = tmp.name
    
    with open(tmp_path, "rb") as f:
        text = Groq(api_key=GROQ_KEY).audio.transcriptions.create(
            file=f, model=SETTINGS['whisper_model'], response_format="text"
        )
    
    os.unlink(tmp_path)
    return text

def generate_tts_audio(text):
    """Generates audio bytes instead of using Pygame"""
    if not SETTINGS['enable_voice']: return None
    
    async def gen():
        comm = edge_tts.Communicate(text, "en-IN-NeerjaNeural", rate="+10%")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
            tmp_path = tmp.name
        await comm.save(tmp_path)
        return tmp_path
    
    try:
        audio_file_path = asyncio.run(gen())
        with open(audio_file_path, "rb") as f:
            audio_data = f.read()
        os.unlink(audio_file_path)
        return audio_data
    except Exception as e:
        st.error(f"TTS Error: {e}")
        return None

def analyze_frame(frame):
    processed = frame.copy()
    h, w = processed.shape[:2]
    cv2.putText(processed, f"{THEME_CONFIG['app_name']} SCANNING", (10, 40), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 136), 2)
    cv2.rectangle(processed, (0, 0), (w, h), (0, 255, 136), 3)
    return processed

class CloudVisionProcessor(VideoTransformerBase):
    """WebRTC processor for cloud-hosted camera feeds"""
    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        processed_img = analyze_frame(img)
        return av.VideoFrame.from_ndarray(processed_img, format="bgr24")

def get_pdfs():
    if not os.path.exists(PDF_FOLDER): return []
    return [f for f in os.listdir(PDF_FOLDER) if f.endswith('.pdf')]

def main():
    st.set_page_config(
        page_title=THEME_CONFIG['app_name'], 
        page_icon="üå±", 
        layout="wide"
    )
    
    st.markdown(f"""
    <style>
    @import url('https://fonts.googleapis.com/css2?family={THEME_CONFIG['font_family'].replace(' ', '+')}:wght@300;400;600;700&display=swap');
    
    .stApp {{
        background: linear-gradient(135deg, 
            {THEME_CONFIG['background_gradient_start']} 0%, 
            {THEME_CONFIG['background_gradient_mid']} 50%, 
            {THEME_CONFIG['background_gradient_end']} 100%);
        font-family: '{THEME_CONFIG['font_family']}', sans-serif;
    }}
    
    .block-container {{
        background: rgba(255, 255, 255, {THEME_CONFIG['glass_opacity']});
        backdrop-filter: blur({THEME_CONFIG['glass_blur']});
        border-radius: 20px;
        padding: 2rem !important;
    }}
    
    h1, h2, h3 {{
        color: {THEME_CONFIG['primary_color']} !important;
        text-shadow: 0 0 20px {THEME_CONFIG['primary_color']}80;
        font-family: '{THEME_CONFIG['font_family']}', sans-serif;
    }}
    
    section[data-testid="stSidebar"] {{
        background: rgba(255, 255, 255, {THEME_CONFIG['glass_opacity']}) !important;
        backdrop-filter: blur(15px) !important;
    }}
    
    .stButton>button {{
        background: rgba(0, 255, 136, 0.15) !important;
        backdrop-filter: blur(10px);
        border: 1px solid {THEME_CONFIG['primary_color']}50 !important;
        border-radius: 12px !important;
        color: {THEME_CONFIG['primary_color']} !important;
        font-weight: 600 !important;
    }}
    </style>
    """, unsafe_allow_html=True)
    
    # Session state
    if 'chat' not in st.session_state: st.session_state.chat = []
    if 'client' not in st.session_state: st.session_state.client, st.session_state.vs = init_ai()
    if 'cam' not in st.session_state: st.session_state.cam = False
    
    # Header
    st.markdown(f"<h1 style='text-align: center;'>üå± {THEME_CONFIG['app_name']}</h1>", unsafe_allow_html=True)
    st.markdown(f"<p style='text-align: center; color: {THEME_CONFIG['primary_color']};'>{THEME_CONFIG['app_tagline']}</p>", unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("### üìö Knowledge Base")
        pdfs = get_pdfs()
        if pdfs:
            st.success(f"‚úÖ {len(pdfs)} PDFs loaded")
            with st.expander("View PDFs"):
                for pdf in pdfs: st.text(f"üìÑ {pdf}")
        else:
            st.info("No PDFs. Use admin panel to upload.")
        
        st.markdown("### ‚öôÔ∏è Settings")
        if SETTINGS['enable_camera']:
            st.session_state.cam = st.toggle("üìπ Camera", value=st.session_state.cam)
        
        if st.button("üóëÔ∏è Clear Chat"): 
            st.session_state.chat = []
            st.rerun()
    
    col1, col2 = st.columns([1, 1])
    
    # Left Column: Camera
    with col1:
        st.markdown("### üìπ Smart Camera")
        if SETTINGS['enable_camera'] and st.session_state.cam:
            webrtc_streamer(
                key="agri-vision",
                video_transformer_factory=CloudVisionProcessor,
                rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
            )
        else:
            status = "Camera disabled in settings" if not SETTINGS['enable_camera'] else "Camera off"
            st.info(f"üìπ {status}")

    # Right Column: Chat & Voice
    with col2:
        st.markdown("### üí¨ Chat Assistant")
        
        chat_ph = st.container(height=350, border=True)
        with chat_ph:
            if not st.session_state.chat:
                st.info("üëã Hello! Ask me anything about agriculture.")
            else:
                for msg in st.session_state.chat:
                    with st.chat_message(msg['role']):
                        st.markdown(msg['content'])
        
        # Cloud-Safe Audio Input Widget
        audio_input_bytes = None
        if SETTINGS['enable_voice']:
            audio_input_bytes = st.audio_input("üé§ Record Voice Query")

        # Text Input
        user_input = st.chat_input("Or type your question here...")

        prompt = None
        if audio_input_bytes:
            with st.spinner("Transcribing..."):
                prompt = speech_to_text(audio_input_bytes)
        elif user_input:
            prompt = user_input
        
        if prompt:
            st.session_state.chat.append({'role': 'user', 'content': prompt})
            
            with st.spinner("ü§î Thinking..."):
                response = ask_ai(prompt, st.session_state.client, st.session_state.vs)
            
            st.session_state.chat.append({'role': 'assistant', 'content': response})
            
            # Cloud-Safe Audio Output (Autoplay)
            if SETTINGS['enable_voice']:
                tts_audio = generate_tts_audio(response)
                if tts_audio:
                    st.audio(tts_audio, format="audio/mp3", autoplay=True)
            
            st.rerun()

if __name__ == "__main__":
    main()
